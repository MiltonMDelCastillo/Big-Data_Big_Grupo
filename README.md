Sistema de Ingesta en Tiempo Real con Kafka + API REST 

 

Este mÃ³dulo implementa un pipeline de ingesta en tiempo real utilizando: 

API REST (Python â€“ Flask/FastAPI) 

Apache Kafka (productor/consumidor) 

Docker + Docker Compose 

Postman para pruebas 

Procesamiento en vivo 

El objetivo es recibir datos desde sensores, enviarlos a Kafka y procesarlos en tiempo real. 

0) Requisitos Previos 

AsegÃºrate de tener instalado: 

Docker + Docker Desktop 

Python 3.10+ 

Postman (opcional, para pruebas) 

VS Code u otro editor 

(Opcional) Kafka UI 

1) Clonar y Configurar el Proyecto 

# Copiar mÃ³dulo dentro del proyecto principal 
cp -r realtime_kafka ./integranteX_realtime 
cd integranteX_realtime 

Crear archivo .env: 

cp .env.example .env 

Variables por defecto: 

KAFKA_BROKER=localhost:9092 
TOPIC_NAME=sensor_data 
API_PORT=5000 

Edita si deseas cambiar valores. 

2) Levantar Kafka con Docker 

Ejecuta: 

docker compose up -d 

Esto inicia: 

Zookeeper 

Kafka Broker 

Kafka UI (si estÃ¡ configurado) 

Verifica que estÃ¡ corriendo: 

docker ps 
 

3) Ejecutar la API REST 

Crear entorno virtual: 

python -m venv venv 
source venv/bin/activate      # Windows: venv\Scripts\activate 

Instalar dependencias: 

pip install -r requirements.txt 

Iniciar la API: 

python main.py 
 

Salida esperada: 

Running on http://127.0.0.1:5000 
Running on http://0.0.0.0:5000 

 
 
 

4) Probar la API con Postman 

Abre Postman â†’ Create Request â†’ MÃ©todo POST 

URL: 

http://127.0.0.1:5000/sensor 

Body â†’ raw â†’ JSON 

{ 
 "sensor_id": "sensor01", 
 "timestamp": "2025-11-17T14:20:00Z", 
 "type": "temperature", 
 "value": 25.3, 
 "unit": "C", 
 "location": "lab" 
} 

âœ” La API recibe los datos 
âœ” Los envÃ­a a Kafka 

ðŸŽ§ 5) Ejecutar el Consumer de Kafka 

En otra terminal: 

python consumer.py 

Salida esperada: 

Listening to topic: sensor_data 
Message received: {"sensor_id":"sensor01","value":25.3,...} 

6) Flujo Completo del Sistema 

[Cliente/Postman/App] 
         â†“ 
  API Python (Producer) 
         â†“ 
      Kafka Topic 
         â†“ 
  Consumer en Python 
         â†“ 
  BD / Dashboards / Procesamiento 

7) Problemas Comunes y Soluciones 

ECONNREFUSED 127.0.0.1:5000 

SoluciÃ³n: 

Verifica que la API estÃ© encendida 

Usa la IP que aparece en consola (a veces cambia) 

Kafka no conecta 

SoluciÃ³n: 

docker compose logs kafka 

 
8) Criterios de AceptaciÃ³n (Performance) 

API debe aceptar â‰¥ 100 req/s 

Kafka debe recibir todos los mensajes sin pÃ©rdida 

Latencia total del pipeline < 200 ms 

Consumer debe procesar en tiempo real 

Servicios deben funcionar con Docker o localmente 

 

9) Extensiones Opcionales 

Puedes integrar: 

Almacenamiento en PostgreSQL, MongoDB o TimescaleDB 

Dashboard con Grafana 

Kafka UI para visualizar mensajes 

Autor 

Proyecto desarrollado por [Milton Martinez] 
Universidad del Valle â€“ IngenierÃ­a de Sistemas e InformÃ¡tica 

 
